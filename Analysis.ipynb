{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e47729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()\n",
    "#https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d7a728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'create_words.out': [('added', 'VBD'), ('available', 'JJ'), ('consumed', 'VBN'), ('created', 'VBN'), ('creation', 'NN'), ('current', 'JJ'), ('default', 'NN'), ('demand', 'NN'), ('exchange', 'NN'), ('indicates', 'VBZ'), ('item', 'JJ'), ('line', 'NN'), ('made', 'VBD'), ('need', 'MD'), ('new', 'JJ'), ('order', 'NN'), ('payment', 'NN'), ('purpose', 'JJ'), ('return', 'NN'), ('set', 'VBN'), ('status', 'NN'), ('system', 'NN'), ('used', 'VBN'), ('valid', 'JJ'), ('value', 'NN'), ('whether', 'IN'), ('work', 'NN')], 'hold_words.out': [('applied', 'VBN'), ('customer', 'NN'), ('default', 'NN'), ('hold', 'VBP'), ('limit', 'NN'), ('line', 'NN'), ('order', 'NN'), ('payment', 'NN'), ('placed', 'VBD'), ('resolved', 'JJ'), ('transaction', 'NN'), ('type', 'NN'), ('user', 'NN'), ('valid', 'JJ'), ('value', 'NN'), ('whether', 'IN')], 'inventory_words.out': [('adjustment', 'NN'), ('allow', 'NN'), ('always', 'RB'), ('applies', 'VBZ'), ('arrived', 'VBN'), ('associated', 'VBN'), ('attribute', 'JJ'), ('audit', 'NN'), ('cancelled', 'VBN'), ('capacity', 'NN'), ('category', 'NN'), ('change', 'NN'), ('considered', 'VBN'), ('customer', 'NN'), ('customized', 'VBN'), ('date', 'NN'), ('default', 'NN'), ('delivery', 'NN'), ('determines', 'VBZ'), ('different', 'JJ'), ('enterprise', 'NN'), ('following', 'VBG'), ('foreign', 'JJ'), ('ignored', 'VBN'), ('indicates', 'VBZ'), ('inventory', 'JJ'), ('item', 'NN'), ('ITEM', 'NNP'), ('line', 'NN'), ('logical', 'JJ'), ('need', 'NN'), ('node', 'IN'), ('none', 'NN'), ('noneyfs', 'NN'), ('order', 'NN'), ('ordered', 'VBD'), ('passed', 'VBN'), ('posted', 'VBN'), ('pricing', 'VBG'), ('product', 'NN'), ('provided', 'VBD'), ('purchase', 'NN'), ('quantity', 'NN'), ('receipt', 'NN'), ('reference', 'NN'), ('result', 'NN'), ('service', 'NN'), ('ship', 'NN'), ('shortage', 'NN'), ('status', 'NN'), ('stock', 'NN'), ('table', 'NN'), ('UOM', 'NNP'), ('used', 'VBD'), ('valid', 'JJ'), ('value', 'NN'), ('whether', 'IN')], 'invoice_words.out': [('adjustment', 'NN'), ('amount', 'NN'), ('applicable', 'JJ'), ('associated', 'VBN'), ('charge', 'NN'), ('event', 'NN'), ('invoice', 'NN'), ('invoiced', 'VBD'), ('item', 'NN'), ('line', 'NN'), ('order', 'NN'), ('per', 'IN'), ('price', 'NN'), ('unit', 'NN')], 'release_words.out': [('associated', 'VBN'), ('calendar', 'NN'), ('default', 'NN'), ('following', 'VBG'), ('foreign', 'JJ'), ('fulfilled', 'JJ'), ('header', 'NN'), ('identify', 'VB'), ('indicates', 'VBZ'), ('line', 'NN'), ('logical', 'JJ'), ('made', 'VBD'), ('minimum', 'JJ'), ('node', 'JJ'), ('none', 'NN'), ('noneyfs', 'JJ'), ('order', 'NN'), ('orderno', 'NN'), ('process', 'NN'), ('quantity', 'NN'), ('release', 'NN'), ('releaseno', 'NN'), ('rule', 'NN'), ('ship', 'NN'), ('shipment', 'NN'), ('shipped', 'VBD'), ('shipping', 'VBG'), ('single', 'JJ'), ('table', 'NN'), ('uniquely', 'RB'), ('used', 'VBD'), ('value', 'NN'), ('whether', 'IN')], 'schedule_words.out': [('allowed', 'VBN'), ('indicates', 'NNS'), ('line', 'NN'), ('node', 'JJ'), ('order', 'NN'), ('schedule', 'NN'), ('scheduled', 'VBN'), ('scheduling', 'VBG'), ('ship', 'NN'), ('used', 'VBD'), ('whether', 'IN')], 'ship_words.out': [('address', 'NN'), ('applies', 'NNS'), ('applying', 'VBG'), ('associated', 'VBN'), ('bill', 'NN'), ('calendar', 'NN'), ('category', 'NN'), ('charge', 'NN'), ('cost', 'NN'), ('creation', 'NN'), ('customer', 'NN'), ('date', 'NN'), ('day', 'NN'), ('default', 'NN'), ('defaulted', 'VBD'), ('determine', 'JJ'), ('drop', 'NN'), ('expected', 'VBD'), ('following', 'VBG'), ('foreign', 'JJ'), ('fulfilled', 'JJ'), ('handling', 'VBG'), ('header', 'NN'), ('hour', 'NN'), ('identifier', 'NN'), ('incoming', 'VBG'), ('indicates', 'VBZ'), ('inventory', 'JJ'), ('item', 'NN'), ('line', 'NN'), ('logical', 'JJ'), ('made', 'VBD'), ('minimum', 'JJ'), ('node', 'JJ'), ('none', 'NN'), ('noneyfs', 'RB'), ('one', 'CD'), ('order', 'NN'), ('organization', 'NN'), ('otherwise', 'RB'), ('pricing', 'VBG'), ('process', 'NN'), ('procurement', 'NN'), ('provided', 'VBD'), ('quantity', 'NN'), ('receipt', 'NN'), ('receiving', 'VBG'), ('release', 'NN'), ('rule', 'NN'), ('schedule', 'NN'), ('ship', 'NN'), ('shipment', 'NN'), ('shipped', 'VBD'), ('shipping', 'VBG'), ('specified', 'VBN'), ('surcharge', 'NN'), ('system', 'NN'), ('table', 'JJ'), ('tax', 'NN'), ('tier', 'NN'), ('time', 'NN'), ('total', 'JJ'), ('transaction', 'NN'), ('unit', 'NN'), ('used', 'VBN'), ('valid', 'JJ'), ('value', 'NN'), ('weight', 'VBD'), ('whether', 'IN'), ('within', 'IN')]}\n"
     ]
    }
   ],
   "source": [
    "import nltk.tokenize as nt\n",
    "import nltk\n",
    "\n",
    "#reference_tasks = ['create','hold','release','schedule','release','invoice','ship']\n",
    "#reference_entities = ['order','node','organization','line','address','shipment']\n",
    "filenames = ['create_words.out','hold_words.out','inventory_words.out','invoice_words.out',\n",
    "             'release_words.out','schedule_words.out','ship_words.out']\n",
    "\n",
    "class nlpdict(dict): \n",
    "  \n",
    "    # __init__ function \n",
    "    def __init__(self): \n",
    "        self = dict() \n",
    "          \n",
    "    # Function to add key:value \n",
    "    def add(self, key, value): \n",
    "        self[key] = value\n",
    "\n",
    "nlpdictobj = nlpdict()\n",
    "for fname in filenames:\n",
    "    with open(fname, \"r\") as fin:\n",
    "        mylist = fin.read().splitlines()\n",
    "        pos=nltk.pos_tag(mylist)\n",
    "        nlpdictobj.add(fname,pos)\n",
    "\n",
    "print(nlpdictobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05cfc96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "class wordcombo:\n",
    "    concept = ''\n",
    "    nouns,verbs,adjectives=set(),set(),set()\n",
    "    def __init__(self,c,n,v,a):\n",
    "        self.concept = c\n",
    "        self.nouns = n\n",
    "        self.verbs = v\n",
    "        self.adjectives = a\n",
    "\n",
    "wordcombos=[]\n",
    "for key in nlpdictobj:\n",
    "    a,c,n,v=set(),set(),set(),set()\n",
    "    for word,tag in nlpdictobj[key]:\n",
    "        if tag.startswith(\"N\"):\n",
    "            n.add(word)\n",
    "        elif tag.startswith(\"V\"):\n",
    "            v.add(word)\n",
    "        elif tag.startswith(\"J\"):\n",
    "            a.add(word)\n",
    "    mywc = wordcombo(key,n,v,a)\n",
    "    wordcombos.append(mywc)\n",
    "\n",
    "print(len(wordcombos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56dd5d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(wordcombos[0].nouns)\n",
    "rulesetfiles = ['create_rules.out','hold_rules.out','inventory_rules.out','invoice_rules.out',\n",
    "             'release_rules.out','schedule_rules.out','ship_rules.out']\n",
    "for rulesetfile in rulesetfiles:\n",
    "    with open(rulesetfile, 'r') as frin:\n",
    "        wordfile=rulesetfile.split('_')[0]\n",
    "        shortrulefile = wordfile + \"_shortrules.out\"\n",
    "        wordfile+= '_words.out'\n",
    "        with open(shortrulefile, 'w') as frout:\n",
    "            mywc = None\n",
    "            for wc in wordcombos:\n",
    "                if wc.concept == wordfile:\n",
    "                    mywc = wc\n",
    "                    break\n",
    "            if mywc == None:\n",
    "                print(\"Skipping \" + rulesetfile)\n",
    "                continue\n",
    "            nounRules, verbRules = set(),set()\n",
    "            mylist = frin.read().splitlines()\n",
    "            for row in mylist:\n",
    "                #check if antecedent has {noun, verb} or {noun, noun}\n",
    "                #print(row)\n",
    "                words = row.split(',')\n",
    "                #There are 7 parts to a row.\n",
    "                #print(words)\n",
    "                ante,cons,lift,conv=set(words[1].split(' ')),set(words[2].split(' ')),words[5],words[6]\n",
    "                antelist.append(words[1]), conslist.append(words[2])\n",
    "                #print('checking ' + str(ante) + ' with ' + str(mywc.nouns))\n",
    "                antenouns,anteverbs = mywc.nouns.intersection(ante),mywc.verbs.intersection(ante)\n",
    "                consnouns,consverbs = mywc.nouns.intersection(cons),mywc.verbs.intersection(cons)\n",
    "                if len(antenouns) < 2 or len(consnouns) == 0:\n",
    "                    continue;\n",
    "                if len(antenouns) >= 1 and len(anteverbs) >= 1 and len(consnouns) >= 1 and len(consverbs) >= 1:\n",
    "                    verbRules.add(row)\n",
    "                if len(antenouns) >= 1 and len(consnouns) >= 1:\n",
    "                    nounRules.add(row)\n",
    "            #we should have short list of rules, let us weed out converse rules by lift or Conviction\n",
    "            i=0\n",
    "            midrules=verbRules.union(nounRules)\n",
    "            #print(verbRules), print(nounRules)\n",
    "            midlist=list(midrules)\n",
    "            finalrules=set()\n",
    "            antelist,conslist,liftlist,convlist=[],[],[],[]\n",
    "            for rule in midlist:\n",
    "                words = rule.split(',')\n",
    "                antelist.append(words[1]), conslist.append(words[2]), liftlist.append(words[5]), convlist.append(words[6])\n",
    "            for ante in antelist:\n",
    "                i+=1\n",
    "                try:\n",
    "                    idx = conslist.index(ante)\n",
    "                    if antelist[idx] == conslist[i-1]:\n",
    "                        #mylist[i-1] and mylist[idx] are converse rules- Keep one with higher lift or conviction\n",
    "                        lift1,conv1,lift2,conv2 = liftlist[i-1],convlist[i-1],liftlist[idx],convlist[idx]\n",
    "                        if lift1 > lift2:\n",
    "                            finalrules.add(midlist[i-1])\n",
    "                        elif lift1 < lift2:\n",
    "                            finalrules.add(midlist[idx])\n",
    "                        elif conv1 > conv2:\n",
    "                            finalrules.add(midlist[i-1])\n",
    "                        else:\n",
    "                            finalrules.add(midlist[idx])\n",
    "                except ValueError:\n",
    "                    finalrules.add(mylist[i-1])\n",
    "                    continue\n",
    "            for rule in finalrules:\n",
    "                frout.write(str(rule) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ec38d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
